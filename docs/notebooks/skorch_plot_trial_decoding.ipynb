{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)  # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "90 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 90 events and 497 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 22  # carefully cherry-picked to give nice results on such limited data :)\n",
    "event_codes = [5, 6, 9, 10, 13, 14]\n",
    "# event_codes = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True, stim_channel='auto',\n",
    "                             verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = \\\n",
    "    mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands_or_left=2, feet_or_right=3),\n",
    "                     tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                     baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\n",
    "\n",
    "\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "# in skorch flow it is also a validation set (train-valid split set in skorch model)\n",
    "# To not shuffle data for train-valid split we need to create a splitter\n",
    "train_set = SignalAndTarget(X[:70], y=y[:70])\n",
    "# valid_set = SignalAndTarget(X[40:70], y=y[40:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from braindecode.torch_ext.util import set_random_seeds  # XXX : move to braindecode.util\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/.virtualenvs/braindecode/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from skorch.classifier import NeuralNet, NeuralNetClassifier\n",
    "from skorch.dataset import CVSplit\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reshape(-1, 64, 497, 1)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = EEGDataSet(train_set.X, train_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter:\n",
    "    def __init__(self, train_size):\n",
    "        assert isinstance(train_size, (int, float))\n",
    "        self.train_size = train_size\n",
    "        \n",
    "    def __call__(self, dataset, y, **kwargs):\n",
    "        if isinstance(self.train_size, int):\n",
    "            dataset_train = EEGDataSet(dataset.X[:self.train_size],dataset.y[:self.train_size])\n",
    "            dataset_valid = EEGDataSet(dataset.X[self.train_size:], dataset.y[self.train_size:])\n",
    "#             dataset_train = torch.utils.data.Subset(dataset, range(0, self.train_size))\n",
    "#             dataset_valid = torch.utils.data.Subset(dataset, range(self.train_size, len(X)))\n",
    "        elif isinstance(self.train_size, float):\n",
    "            raise Exception\n",
    "            dataset_train = torch.utils.data.Subset(dataset, range(\n",
    "                0, int(self.train_size * len(dataset))))\n",
    "            dataset_valid = torch.utils.data.Subset(dataset, range(\n",
    "                int(self.train_size * len(dataset)), len(X)))\n",
    "        return dataset_train, dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto').create_network()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# It can use also NeuralNetClassifier\n",
    "skorch_model = NeuralNet(model,\n",
    "                         criterion=torch.nn.NLLLoss,\n",
    "                         optimizer=optim.Adam, train_split=Splitter(40),\n",
    "                         optimizer__lr=0.0625 * 0.01, optimizer__weight_decay=0, batch_size=64)\n",
    "        \n",
    "#                                   )#Splitter(40))#, callbacks=[('accuracy', EpochScoring('accuracy', lower_is_better=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.6128\u001b[0m        \u001b[32m0.8567\u001b[0m  0.7583\n",
      "      2        \u001b[36m0.6304\u001b[0m        1.0264  0.5937\n",
      "      3        \u001b[36m0.3136\u001b[0m        \u001b[32m0.8096\u001b[0m  0.6120\n",
      "      4        0.4003        \u001b[32m0.6471\u001b[0m  0.6609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=Sequential(\n",
       "    (dimshuffle): Expression(expression=_transpose_time_to_spat)\n",
       "    (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))\n",
       "    (conv_spat): Conv2d(40, 40, kernel_size=(1, 64), stride=(1, 1), bias=False)\n",
       "    (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_nonlin): Expression(expression=square)\n",
       "    (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)\n",
       "    (pool_nonlin): Expression(expression=safe_log)\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "    (conv_classifier): Conv2d(40, 2, kernel_size=(27, 1), stride=(1, 1))\n",
       "    (softmax): LogSoftmax()\n",
       "    (squeeze): Expression(expression=_squeeze_final_output)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_model.fit(train_set, y=None, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7dae85b3a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0625\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ## Run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/braindecode/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "# from braindecode.torch_ext.optimizers import AdamW\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "# optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = Adam(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)\n",
    "\n",
    "# ## Run the training\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "n_epochs = 4\n",
    "model.fit(train_set.X, train_set.y, n_epochs=n_epochs, batch_size=64,\n",
    "          scheduler='cosine', validation_data=(valid_set.X, valid_set.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The monitored values are also stored into a pandas dataframe:\n",
    "\n",
    "model.epochs_df\n",
    "\n",
    "# Eventually, we arrive at 83.4% accuracy, so 25 from 30 trials are correctly\n",
    "# predicted. In the [Cropped Decoding Tutorial](./Cropped_Decoding.html),\n",
    "# we can learn how to achieve higher accuracies using cropped training.\n",
    "\n",
    "##############################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "\n",
    "# Once we have all our hyperparameters and architectural choices done, we\n",
    "# can evaluate the accuracies to report in our publication by evaluating on\n",
    "# the test set:\n",
    "\n",
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model.evaluate(test_set.X, test_set.y)\n",
    "\n",
    "# We can also retrieve predicted labels per trial as such:\n",
    "\n",
    "y_pred = model.predict(test_set.X)\n",
    "\n",
    "# We can also retrieve the raw network outputs per trial as such:\n",
    "#\n",
    "# <div class=\"alert alert-warning\">\n",
    "# Note these are log-softmax outputs, so to get probabilities one would\n",
    "# have to exponentiate them using `th.exp`.\n",
    "# </div>\n",
    "\n",
    "model.predict_outs(test_set.X)\n",
    "\n",
    "# <div class=\"alert alert-info\">\n",
    "#\n",
    "# If you want to try cross-subject decoding, changing the loading code to\n",
    "# the following will perform cross-subject decoding on imagined left vs\n",
    "# right hand closing, with 50 training and 5 validation subjects\n",
    "# (Warning, might be very slow if you are on CPU):\n",
    "#\n",
    "# </div>\n",
    "\n",
    "from braindecode.datautil import SignalAndTarget\n",
    "\n",
    "# First 50 subjects as train\n",
    "physionet_paths = [mne.datasets.eegbci.load_data(sub_id, [4, 8, 12])\n",
    "                   for sub_id in range(1, 51)]\n",
    "physionet_paths = np.concatenate(physionet_paths)\n",
    "parts = [mne.io.read_raw_edf(path, preload=True, stim_channel='auto')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False,\n",
    "                       eog=False, exclude='bads')\n",
    "\n",
    "# Find the events in this dataset\n",
    "events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1,\n",
    "                     tmax=4.1, proj=False, picks=picks,\n",
    "                     baseline=None, preload=True)\n",
    "\n",
    "# 51-55 as validation subjects\n",
    "physionet_paths_valid = [mne.datasets.eegbci.load_data(sub_id, [4, 8, 12])\n",
    "                         for sub_id in range(51, 56)]\n",
    "physionet_paths_valid = np.concatenate(physionet_paths_valid)\n",
    "parts_valid = [mne.io.read_raw_edf(path, preload=True, stim_channel='auto')\n",
    "               for path in physionet_paths_valid]\n",
    "raw_valid = concatenate_raws(parts_valid)\n",
    "\n",
    "picks_valid = mne.pick_types(raw_valid.info, meg=False, eeg=True,\n",
    "                             stim=False, eog=False,\n",
    "                             exclude='bads')\n",
    "\n",
    "events_valid, _ = mne.events_from_annotations(raw_valid)\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched_valid = mne.Epochs(raw_valid, events_valid, dict(hands=2, feet=3),\n",
    "                           tmin=1, tmax=4.1, proj=False, picks=picks_valid,\n",
    "                           baseline=None, preload=True)\n",
    "\n",
    "train_X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "train_y = (epoched.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\n",
    "valid_X = (epoched_valid.get_data() * 1e6).astype(np.float32)\n",
    "valid_y = (epoched_valid.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\n",
    "train_set = SignalAndTarget(train_X, y=train_y)\n",
    "valid_set = SignalAndTarget(valid_X, y=valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
