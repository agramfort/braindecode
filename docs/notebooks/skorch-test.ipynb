{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "90 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "Loading data for 90 events and 497 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 1\n",
    "event_codes = [5, 6, 9, 10, 13, 14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True, stim_channel='auto',\n",
    "                             verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False,\n",
    "                                  eog=False,\n",
    "                                  exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1,\n",
    "                     proj=False, picks=eeg_channel_inds,\n",
    "                     baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\n",
    "\n",
    "train_set = SignalAndTarget(X[:60], y=y[:60])\n",
    "test_set = SignalAndTarget(X[60:], y=y[60:])\n",
    "\n",
    "# train_set, valid_set = split_into_two_sets(train_set,\n",
    "#                                            first_set_fraction=0.8)\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 450\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=input_time_length,\n",
    "                        final_conv_length=12).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(\n",
    "    np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, \\\n",
    "    CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator is used to iterate over datasets both for training\n",
    "# and evaluation\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,\n",
    "                                   input_time_length=input_time_length,\n",
    "                                   n_preds_per_input=n_preds_per_input)\n",
    "\n",
    "# Loss function takes predictions as they come out of the network and the targets\n",
    "# and returns a loss\n",
    "class LossFunction:\n",
    "    def __call__(self, preds, targets):\n",
    "        return F.nll_loss(th.mean(preds, dim=2, keepdim=False), targets)\n",
    "# loss_function = lambda preds, targets: F.nll_loss(\n",
    "#     th.mean(preds, dim=2, keepdim=False), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be used to apply some constraint on the models, then should be object\n",
    "# with apply method that accepts a module\n",
    "model_constraint = None\n",
    "# Monitors log the training progress\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length),\n",
    "            RuntimeMonitor(), ]\n",
    "# Stop criterion determines when the first stop happens\n",
    "stop_criterion = MaxEpochs(4)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator,\n",
    "                 loss_function, optimizer, model_constraint,\n",
    "                 monitors, stop_criterion,\n",
    "                 remember_best_column='valid_misclass',\n",
    "                 run_after_early_stop=True, batch_modifier=None, cuda=cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.classifier import NeuralNet\n",
    "from skorch.dataset import CVSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reshape(-1, 64, 497, 1)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = EEGDataSet(train_set.X, train_set.y)\n",
    "valid_set = EEGDataSet(valid_set.X, valid_set.y)\n",
    "test_set = EEGDataSet(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_score(net, X=None, y=None):\n",
    "    losses = net.history[-1, 'batches', :, 'my_score']\n",
    "    batch_sizes = net.history[-1, 'batches', :, 'valid_batch_size']\n",
    "    return np.average(losses, weights=batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "skorch_model = NeuralNet(model, LossFunction, optim.Adam, train_split=CVSplit(cv=0.5))\n",
    "#, callbacks=[('accuracy', EpochScoring('accuracy', lower_is_better=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.6107\u001b[0m        \u001b[32m1.1428\u001b[0m  0.8415\n",
      "      2        \u001b[36m0.7609\u001b[0m        1.9469  0.7551\n",
      "      3        0.8753        2.3047  0.6911\n",
      "      4        0.7719        2.5271  0.7515\n",
      "      5        \u001b[36m0.5634\u001b[0m        2.3662  0.8819\n",
      "      6        \u001b[36m0.4354\u001b[0m        2.0589  0.6537\n",
      "      7        \u001b[36m0.3999\u001b[0m        1.7215  0.7479\n",
      "      8        \u001b[36m0.3861\u001b[0m        1.4272  0.7418\n",
      "      9        \u001b[36m0.3513\u001b[0m        1.2497  0.8589\n",
      "     10        \u001b[36m0.2934\u001b[0m        1.1590  0.7061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=Sequential(\n",
       "    (dimshuffle): Expression(expression=_transpose_time_to_spat)\n",
       "    (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))\n",
       "    (conv_spat): Conv2d(40, 40, kernel_size=(1, 64), stride=(1, 1), bias=False)\n",
       "    (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_nonlin): Expression(expression=square)\n",
       "    (pool): AvgPool2d(kernel_size=(75, 1), stride=(1, 1), padding=0)\n",
       "    (pool_nonlin): Expression(expression=safe_log)\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "    (conv_classifier): Conv2d(40, 2, kernel_size=(12, 1), stride=(1, 1), dilation=(15, 1))\n",
       "    (softmax): LogSoftmax()\n",
       "    (squeeze): Expression(expression=_squeeze_final_output)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.63512123e-01, 3.64879258e-02],\n",
       "       [5.23885548e-01, 4.76114452e-01],\n",
       "       [9.90216255e-01, 9.78377461e-03],\n",
       "       [7.01407790e-01, 2.98592210e-01],\n",
       "       [9.64998662e-01, 3.50013748e-02],\n",
       "       [9.72419262e-01, 2.75806896e-02],\n",
       "       [9.99376595e-01, 6.23407948e-04],\n",
       "       [9.57187772e-01, 4.28122766e-02],\n",
       "       [9.91731703e-01, 8.26831348e-03],\n",
       "       [8.05356026e-01, 1.94643915e-01],\n",
       "       [9.55760002e-01, 4.42399830e-02],\n",
       "       [9.43263650e-01, 5.67363240e-02],\n",
       "       [9.64158475e-01, 3.58414575e-02],\n",
       "       [9.88989055e-01, 1.10110017e-02],\n",
       "       [3.28940988e-01, 6.71059012e-01],\n",
       "       [1.61786646e-01, 8.38213384e-01],\n",
       "       [6.85525835e-01, 3.14474195e-01],\n",
       "       [3.44549865e-01, 6.55450106e-01],\n",
       "       [9.95098531e-01, 4.90145013e-03],\n",
       "       [9.56322134e-01, 4.36779149e-02],\n",
       "       [8.98032606e-01, 1.01967342e-01],\n",
       "       [9.87291157e-01, 1.27088986e-02],\n",
       "       [9.64792788e-01, 3.52071822e-02],\n",
       "       [8.82885337e-01, 1.17114596e-01],\n",
       "       [9.48732913e-01, 5.12671098e-02],\n",
       "       [9.96182859e-01, 3.81712569e-03],\n",
       "       [9.73291874e-01, 2.67080981e-02],\n",
       "       [7.12546825e-01, 2.87453175e-01],\n",
       "       [9.82802689e-01, 1.71973277e-02],\n",
       "       [8.48561406e-01, 1.51438594e-01]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.mean(skorch_model.predict(test_set.X), axis=2, keepdims=False)), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.63512123e-01, 3.64879258e-02],\n",
       "       [5.23885548e-01, 4.76114452e-01],\n",
       "       [9.90216255e-01, 9.78377461e-03],\n",
       "       [7.01407790e-01, 2.98592210e-01],\n",
       "       [9.64998662e-01, 3.50013748e-02],\n",
       "       [9.72419262e-01, 2.75806896e-02],\n",
       "       [9.99376595e-01, 6.23407948e-04],\n",
       "       [9.57187772e-01, 4.28122766e-02],\n",
       "       [9.91731703e-01, 8.26831348e-03],\n",
       "       [8.05356026e-01, 1.94643915e-01],\n",
       "       [9.55760002e-01, 4.42399830e-02],\n",
       "       [9.43263650e-01, 5.67363240e-02],\n",
       "       [9.64158475e-01, 3.58414575e-02],\n",
       "       [9.88989055e-01, 1.10110017e-02],\n",
       "       [3.28940988e-01, 6.71059012e-01],\n",
       "       [1.61786646e-01, 8.38213384e-01],\n",
       "       [6.85525835e-01, 3.14474195e-01],\n",
       "       [3.44549865e-01, 6.55450106e-01],\n",
       "       [9.95098531e-01, 4.90145013e-03],\n",
       "       [9.56322134e-01, 4.36779149e-02],\n",
       "       [8.98032606e-01, 1.01967342e-01],\n",
       "       [9.87291157e-01, 1.27088986e-02],\n",
       "       [9.64792788e-01, 3.52071822e-02],\n",
       "       [8.82885337e-01, 1.17114596e-01],\n",
       "       [9.48732913e-01, 5.12671098e-02],\n",
       "       [9.96182859e-01, 3.81712569e-03],\n",
       "       [9.73291874e-01, 2.67080981e-02],\n",
       "       [7.12546825e-01, 2.87453175e-01],\n",
       "       [9.82802689e-01, 1.71973277e-02],\n",
       "       [8.48561406e-01, 1.51438594e-01]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.mean(skorch_model.predict(test_set.X), axis=2, keepdims=False)), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/.virtualenvs/braindecode/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0398, 0.0213, 0.0411, 0.0212, 0.0400, 0.0401, 0.0415, 0.0368, 0.0412,\n",
       "        0.0290, 0.0375, 0.0377, 0.0400, 0.0410, 0.0106, 0.0065, 0.0239, 0.0131,\n",
       "        0.0404, 0.0395, 0.0351, 0.0409, 0.0397, 0.0334, 0.0360, 0.0411, 0.0403,\n",
       "        0.0263, 0.0404, 0.0247])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.mean(skorch_model.predict(test_set.X), axis=2, keepdims=False)[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/.virtualenvs/braindecode/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7311])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batches': [{'train_loss': 1.6362584829330444, 'train_batch_size': 30},\n",
       "  {'valid_loss': 1.9583241939544678, 'valid_batch_size': 30}],\n",
       " 'epoch': 1,\n",
       " 'train_batch_count': 1,\n",
       " 'valid_batch_count': 1,\n",
       " 'dur': 0.7669932842254639,\n",
       " 'train_loss': 1.6362584829330444,\n",
       " 'train_loss_best': True,\n",
       " 'valid_loss': 1.9583241939544678,\n",
       " 'valid_loss_best': True}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_model.history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
